{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4721e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------\n",
      "Recording\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dc9b02368254>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\speaker-identification-master-edit\\record.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Store data in chunks for 1 seconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mseconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a83a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Done\n",
      "1 Done\n",
      "2 Done\n",
      "3 Done\n",
      "4 Done\n",
      "5 Done\n",
      "6 Done\n",
      "7 Done\n",
      "8 Done\n",
      "9 Done\n",
      "10 Done\n",
      "11 Done\n",
      "12 Done\n",
      "13 Done\n",
      "14 Done\n",
      "15 Done\n",
      "16 Done\n",
      "17 Done\n",
      "18 Done\n",
      "19 Done\n",
      "20 Done\n",
      "21 Done\n",
      "22 Done\n",
      "23 Done\n",
      "24 Done\n",
      "25 Done\n",
      "26 Done\n",
      "27 Done\n",
      "28 Done\n",
      "29 Done\n",
      "30 Done\n",
      "31 Done\n",
      "32 Done\n",
      "33 Done\n",
      "34 Done\n",
      "35 Done\n",
      "36 Done\n",
      "37 Done\n",
      "38 Done\n",
      "39 Done\n",
      "40 Done\n",
      "41 Done\n",
      "42 Done\n",
      "43 Done\n",
      "44 Done\n",
      "45 Done\n",
      "46 Done\n",
      "47 Done\n",
      "48 Done\n",
      "49 Done\n",
      "50 Done\n",
      "51 Done\n",
      "52 Done\n",
      "53 Done\n",
      "54 Done\n",
      "55 Done\n",
      "56 Done\n",
      "57 Done\n",
      "58 Done\n",
      "59 Done\n",
      "60 Done\n",
      "61 Done\n",
      "62 Done\n",
      "63 Done\n",
      "64 Done\n",
      "65 Done\n",
      "66 Done\n",
      "67 Done\n",
      "68 Done\n",
      "69 Done\n",
      "70 Done\n",
      "71 Done\n",
      "72 Done\n",
      "73 Done\n",
      "74 Done\n",
      "75 Done\n",
      "76 Done\n",
      "77 Done\n",
      "78 Done\n",
      "79 Done\n",
      "80 Done\n",
      "81 Done\n",
      "82 Done\n",
      "83 Done\n",
      "84 Done\n",
      "85 Done\n",
      "86 Done\n",
      "87 Done\n",
      "88 Done\n",
      "89 Done\n",
      "90 Done\n",
      "91 Done\n",
      "92 Done\n",
      "93 Done\n",
      "94 Done\n",
      "95 Done\n",
      "96 Done\n",
      "97 Done\n",
      "98 Done\n",
      "99 Done\n",
      "100 Done\n",
      "101 Done\n",
      "102 Done\n",
      "103 Done\n",
      "104 Done\n",
      "105 Done\n",
      "106 Done\n",
      "107 Done\n",
      "108 Done\n",
      "109 Done\n",
      "110 Done\n",
      "111 Done\n",
      "112 Done\n",
      "113 Done\n",
      "114 Done\n",
      "115 Done\n",
      "116 Done\n",
      "117 Done\n",
      "118 Done\n",
      "119 Done\n",
      "120 Done\n",
      "121 Done\n",
      "122 Done\n",
      "123 Done\n",
      "124 Done\n",
      "125 Done\n",
      "126 Done\n",
      "127 Done\n",
      "128 Done\n",
      "129 Done\n",
      "130 Done\n",
      "131 Done\n",
      "132 Done\n",
      "133 Done\n",
      "134 Done\n",
      "135 Done\n",
      "136 Done\n",
      "137 Done\n",
      "138 Done\n",
      "139 Done\n",
      "140 Done\n",
      "141 Done\n",
      "142 Done\n",
      "143 Done\n",
      "144 Done\n",
      "145 Done\n",
      "146 Done\n",
      "147 Done\n",
      "148 Done\n",
      "149 Done\n",
      "150 Done\n",
      "151 Done\n",
      "152 Done\n",
      "153 Done\n",
      "154 Done\n",
      "155 Done\n",
      "156 Done\n",
      "157 Done\n",
      "158 Done\n",
      "159 Done\n",
      "160 Done\n",
      "161 Done\n",
      "162 Done\n",
      "163 Done\n",
      "164 Done\n",
      "165 Done\n",
      "166 Done\n",
      "167 Done\n",
      "168 Done\n",
      "169 Done\n",
      "170 Done\n",
      "171 Done\n",
      "172 Done\n",
      "173 Done\n",
      "174 Done\n",
      "175 Done\n",
      "176 Done\n",
      "177 Done\n",
      "178 Done\n",
      "179 Done\n",
      "180 Done\n",
      "181 Done\n",
      "182 Done\n",
      "183 Done\n",
      "184 Done\n",
      "185 Done\n",
      "186 Done\n",
      "187 Done\n",
      "188 Done\n",
      "189 Done\n",
      "190 Done\n",
      "191 Done\n",
      "192 Done\n",
      "193 Done\n",
      "194 Done\n",
      "195 Done\n",
      "196 Done\n",
      "197 Done\n",
      "198 Done\n",
      "199 Done\n",
      "200 Done\n",
      "201 Done\n",
      "202 Done\n",
      "203 Done\n",
      "204 Done\n",
      "205 Done\n",
      "206 Done\n",
      "207 Done\n",
      "208 Done\n",
      "209 Done\n",
      "210 Done\n",
      "211 Done\n",
      "212 Done\n",
      "213 Done\n",
      "214 Done\n",
      "215 Done\n",
      "216 Done\n",
      "217 Done\n",
      "218 Done\n",
      "219 Done\n",
      "220 Done\n",
      "221 Done\n",
      "222 Done\n",
      "223 Done\n",
      "224 Done\n",
      "225 Done\n",
      "226 Done\n",
      "227 Done\n",
      "228 Done\n",
      "229 Done\n",
      "230 Done\n",
      "231 Done\n",
      "232 Done\n",
      "233 Done\n",
      "234 Done\n",
      "235 Done\n",
      "236 Done\n",
      "237 Done\n",
      "238 Done\n",
      "239 Done\n",
      "240 Done\n",
      "241 Done\n",
      "242 Done\n",
      "243 Done\n",
      "244 Done\n",
      "245 Done\n",
      "246 Done\n",
      "247 Done\n",
      "248 Done\n",
      "249 Done\n",
      "250 Done\n",
      "251 Done\n",
      "252 Done\n",
      "253 Done\n",
      "254 Done\n",
      "255 Done\n",
      "256 Done\n",
      "257 Done\n",
      "258 Done\n",
      "259 Done\n",
      "260 Done\n",
      "261 Done\n",
      "262 Done\n",
      "263 Done\n",
      "264 Done\n",
      "265 Done\n",
      "266 Done\n",
      "267 Done\n",
      "268 Done\n",
      "269 Done\n",
      "270 Done\n",
      "271 Done\n",
      "272 Done\n",
      "273 Done\n",
      "274 Done\n",
      "275 Done\n",
      "276 Done\n",
      "277 Done\n",
      "278 Done\n",
      "279 Done\n",
      "280 Done\n",
      "281 Done\n",
      "282 Done\n",
      "283 Done\n",
      "284 Done\n",
      "285 Done\n",
      "286 Done\n",
      "287 Done\n",
      "288 Done\n",
      "289 Done\n",
      "290 Done\n",
      "291 Done\n",
      "292 Done\n",
      "293 Done\n",
      "294 Done\n",
      "295 Done\n",
      "296 Done\n",
      "297 Done\n",
      "298 Done\n",
      "299 Done\n",
      "300 Done\n",
      "301 Done\n",
      "302 Done\n",
      "303 Done\n",
      "304 Done\n",
      "305 Done\n",
      "306 Done\n",
      "307 Done\n",
      "308 Done\n",
      "309 Done\n",
      "310 Done\n",
      "311 Done\n",
      "312 Done\n",
      "313 Done\n",
      "314 Done\n",
      "315 Done\n",
      "316 Done\n",
      "317 Done\n",
      "318 Done\n",
      "319 Done\n",
      "320 Done\n",
      "321 Done\n",
      "322 Done\n",
      "323 Done\n",
      "324 Done\n",
      "325 Done\n",
      "326 Done\n",
      "327 Done\n",
      "328 Done\n",
      "329 Done\n",
      "330 Done\n",
      "331 Done\n",
      "332 Done\n",
      "333 Done\n",
      "334 Done\n",
      "335 Done\n",
      "336 Done\n",
      "337 Done\n",
      "338 Done\n",
      "339 Done\n",
      "340 Done\n",
      "341 Done\n",
      "342 Done\n",
      "343 Done\n",
      "344 Done\n",
      "345 Done\n",
      "346 Done\n",
      "347 Done\n",
      "348 Done\n",
      "349 Done\n",
      "350 Done\n",
      "351 Done\n",
      "352 Done\n",
      "353 Done\n",
      "354 Done\n",
      "355 Done\n",
      "356 Done\n",
      "357 Done\n",
      "358 Done\n",
      "359 Done\n",
      "360 Done\n",
      "361 Done\n",
      "362 Done\n",
      "363 Done\n",
      "364 Done\n",
      "365 Done\n",
      "366 Done\n",
      "367 Done\n",
      "368 Done\n",
      "369 Done\n",
      "370 Done\n",
      "371 Done\n",
      "372 Done\n",
      "373 Done\n",
      "374 Done\n",
      "375 Done\n",
      "376 Done\n",
      "377 Done\n",
      "378 Done\n",
      "379 Done\n",
      "380 Done\n",
      "381 Done\n",
      "382 Done\n",
      "383 Done\n",
      "384 Done\n",
      "385 Done\n",
      "386 Done\n",
      "387 Done\n",
      "388 Done\n",
      "389 Done\n",
      "390 Done\n",
      "391 Done\n",
      "392 Done\n",
      "393 Done\n",
      "394 Done\n",
      "395 Done\n",
      "396 Done\n",
      "397 Done\n",
      "398 Done\n",
      "399 Done\n",
      "400 Done\n",
      "401 Done\n",
      "402 Done\n",
      "403 Done\n",
      "404 Done\n",
      "405 Done\n",
      "406 Done\n",
      "407 Done\n",
      "408 Done\n",
      "409 Done\n",
      "410 Done\n",
      "411 Done\n",
      "412 Done\n",
      "413 Done\n",
      "414 Done\n",
      "415 Done\n",
      "416 Done\n",
      "417 Done\n",
      "418 Done\n",
      "419 Done\n",
      "420 Done\n",
      "421 Done\n",
      "422 Done\n",
      "423 Done\n",
      "424 Done\n",
      "425 Done\n",
      "426 Done\n",
      "427 Done\n",
      "428 Done\n",
      "429 Done\n",
      "430 Done\n",
      "431 Done\n",
      "432 Done\n",
      "433 Done\n",
      "434 Done\n",
      "435 Done\n",
      "436 Done\n",
      "437 Done\n",
      "438 Done\n",
      "439 Done\n",
      "440 Done\n",
      "441 Done\n",
      "442 Done\n",
      "443 Done\n",
      "444 Done\n",
      "445 Done\n",
      "446 Done\n",
      "447 Done\n",
      "448 Done\n",
      "449 Done\n",
      "450 Done\n",
      "451 Done\n",
      "452 Done\n",
      "453 Done\n",
      "454 Done\n",
      "455 Done\n",
      "456 Done\n",
      "457 Done\n",
      "458 Done\n",
      "459 Done\n",
      "460 Done\n",
      "461 Done\n",
      "462 Done\n",
      "463 Done\n",
      "464 Done\n",
      "465 Done\n",
      "466 Done\n",
      "467 Done\n",
      "468 Done\n",
      "469 Done\n",
      "470 Done\n",
      "471 Done\n",
      "472 Done\n",
      "473 Done\n",
      "474 Done\n",
      "475 Done\n",
      "476 Done\n",
      "477 Done\n",
      "478 Done\n",
      "479 Done\n",
      "480 Done\n",
      "481 Done\n",
      "482 Done\n",
      "483 Done\n",
      "484 Done\n",
      "485 Done\n",
      "486 Done\n",
      "487 Done\n",
      "488 Done\n",
      "489 Done\n",
      "490 Done\n",
      "491 Done\n",
      "492 Done\n",
      "493 Done\n",
      "494 Done\n",
      "495 Done\n",
      "496 Done\n",
      "497 Done\n",
      "498 Done\n",
      "499 Done\n",
      "500 Done\n",
      "501 Done\n",
      "502 Done\n",
      "503 Done\n",
      "504 Done\n",
      "505 Done\n",
      "506 Done\n",
      "507 Done\n",
      "508 Done\n",
      "509 Done\n",
      "510 Done\n",
      "511 Done\n",
      "512 Done\n",
      "513 Done\n",
      "514 Done\n",
      "515 Done\n",
      "516 Done\n",
      "517 Done\n",
      "518 Done\n",
      "519 Done\n",
      "520 Done\n",
      "521 Done\n",
      "522 Done\n",
      "523 Done\n",
      "524 Done\n",
      "525 Done\n",
      "526 Done\n",
      "527 Done\n",
      "528 Done\n",
      "529 Done\n",
      "530 Done\n",
      "531 Done\n",
      "532 Done\n",
      "533 Done\n",
      "534 Done\n",
      "535 Done\n",
      "536 Done\n",
      "537 Done\n",
      "538 Done\n",
      "539 Done\n",
      "540 Done\n",
      "541 Done\n",
      "542 Done\n",
      "543 Done\n",
      "544 Done\n",
      "545 Done\n",
      "546 Done\n",
      "547 Done\n",
      "548 Done\n",
      "549 Done\n",
      "550 Done\n",
      "551 Done\n",
      "552 Done\n",
      "553 Done\n",
      "554 Done\n",
      "555 Done\n",
      "556 Done\n",
      "557 Done\n",
      "558 Done\n",
      "559 Done\n",
      "560 Done\n",
      "561 Done\n",
      "562 Done\n",
      "563 Done\n",
      "564 Done\n",
      "565 Done\n",
      "566 Done\n",
      "567 Done\n",
      "568 Done\n",
      "569 Done\n",
      "570 Done\n",
      "571 Done\n",
      "572 Done\n",
      "573 Done\n",
      "574 Done\n",
      "575 Done\n",
      "576 Done\n",
      "577 Done\n",
      "578 Done\n",
      "579 Done\n",
      "580 Done\n",
      "581 Done\n",
      "582 Done\n",
      "583 Done\n",
      "584 Done\n",
      "585 Done\n",
      "586 Done\n",
      "587 Done\n",
      "588 Done\n",
      "589 Done\n",
      "590 Done\n",
      "591 Done\n",
      "592 Done\n",
      "593 Done\n",
      "594 Done\n",
      "595 Done\n",
      "596 Done\n",
      "597 Done\n",
      "598 Done\n",
      "599 Done\n",
      "All splited successfully\n"
     ]
    }
   ],
   "source": [
    "import audio_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6a14cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7507 files belonging to 7 directories\n",
      "Sampling rate for C:\\Users\\Yasasi\\speaker-identification-master-edit\\noise\\other\\exercise_bike.wav is incorrect. Ignoring it\n",
      "Sampling rate for C:\\Users\\Yasasi\\speaker-identification-master-edit\\noise\\other\\pink_noise.wav is incorrect. Ignoring it\n",
      "Sampling rate for C:\\Users\\Yasasi\\speaker-identification-master-edit\\noise\\_background_noise_\\10convert.com_Audience-Claps_daSG5fwdA7o.wav is incorrect. Ignoring it\n",
      "Sampling rate for C:\\Users\\Yasasi\\speaker-identification-master-edit\\noise\\_background_noise_\\doing_the_dishes.wav is incorrect. Ignoring it\n",
      "Sampling rate for C:\\Users\\Yasasi\\speaker-identification-master-edit\\noise\\_background_noise_\\dude_miaowing.wav is incorrect. Ignoring it\n",
      "Sampling rate for C:\\Users\\Yasasi\\speaker-identification-master-edit\\noise\\_background_noise_\\running_tap.wav is incorrect. Ignoring it\n",
      "7507 noise files were split into 7501 noise samples where each is 1 sec. long\n",
      "Our class names: ['.ipynb_checkpoints', 'model_keras_tflite', 'Wav', '__pycache__']\n",
      "Processing speaker .ipynb_checkpoints\n",
      "Processing speaker model_keras_tflite\n",
      "Processing speaker Wav\n",
      "Processing speaker __pycache__\n",
      "Found 600 files belonging to 4 classes.\n",
      "Using 540 files for training.\n",
      "Using 60 files for validation.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function add_noise at 0x0000022DAF9F8280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function add_noise at 0x0000022DAF9F8280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000022DC182FDC0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000022DC182FDC0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000022DC182FE50> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000022DC182FE50> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 8000, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 8000, 128)    512         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8000, 128)    0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 8000, 128)    49280       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8000, 128)    0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 8000, 128)    49280       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 8000, 128)    256         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8000, 128)    0           conv1d_17[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8000, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 4000, 128)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d (AveragePooli (None, 1333, 128)    0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 170624)       0           average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          43680000    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 4)            516         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,812,740\n",
      "Trainable params: 43,812,740\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 91s 18s/step - loss: 0.3070 - accuracy: 0.8185 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:From C:\\Users\\Yasasi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Yasasi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model_keras_tflite\\assets\n",
      "updating: model_keras_tflite/ (164 bytes security) (stored 0%)\n",
      "updating: model_keras_tflite/assets/ (164 bytes security) (stored 0%)\n",
      "updating: model_keras_tflite/saved_model.pb (164 bytes security) (deflated 90%)\n",
      "updating: model_keras_tflite/variables/ (164 bytes security) (stored 0%)\n",
      "updating: model_keras_tflite/variables/variables.data-00000-of-00001 (164 bytes security) (deflated 15%)\n",
      "updating: model_keras_tflite/variables/variables.index (164 bytes security) (deflated 70%)\n",
      "2/2 [==============================] - 1s 260ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "[0.0, 1.0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 93 is out of bounds for axis 0 with size 60",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-629b3d45e2b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspeaker_identification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\speaker-identification-master-edit\\speaker_identification.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[1;31m# Take random samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[0mrnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSAMPLES_TO_DISPLAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     \u001b[0maudios\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 93 is out of bounds for axis 0 with size 60"
     ]
    }
   ],
   "source": [
    "import speaker_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d06d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
